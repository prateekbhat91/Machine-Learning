{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "[Naive bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) belongs to the family of generative machine learning models which try to model all the features of the dataset by learning $P(x|y)$ and $P(y)$, where \n",
    "1. $P(x | y)$ = probability of feature given class.\n",
    "2. $P(y)$ = probability of a class.\n",
    "\n",
    "Naive Bayes is based on Bayes Theorem, though being simple it is widely used because it often outperforms more sophisticated classification methods. \n",
    " \n",
    "\n",
    "# Assumptions in Naive Bayes:\n",
    "1. All the features of the data are independent of each other. It is because of this assumption Naive Bayes is called naive.\n",
    "2. The data is IID.\n",
    "\n",
    "\n",
    "# Algorithm:\n",
    "Let us consider a binary classification problem where the classes($C$) are 0 and 1. Assume our data($X$) has $d$ features and $n$ samples. As stated above naive bayes is based on bayes theorem which states that:\n",
    "$$P(C|X) = \\frac{P(X|C)P(C)}{P(X)}$$\n",
    "where,\n",
    "1. P(C|X) is called the prosterior probability of class given predictor.\n",
    "2. P(X|C) is called the likelihood.\n",
    "3. P(C) is called the prior probability(class distribution).\n",
    "4. P(X) is called the prior probability of predictor variable.\n",
    "\n",
    "We need to estimate $P(X|C)$ and $P(C)$ in order to classify a data point. Give a dataset $X = {x_{1},x_{2},x_{3},\n",
    "...,x_{d}}$, we can estimate $P(C|X)$ as \n",
    "$$P(C|X)=\\frac{P(X|C)P(C)}{P(X)} \\propto P(X|C)P(C)$$\n",
    "\n",
    "$$P(C|X) \\propto P(x_{1}|C)P(x_{2}|C)..P(x_{d}|C) P(C)$$\n",
    "\n",
    "**Note:** Naive Bayes learns a linear distriminant fucntion in case of a binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python implemntation:\n",
    "Before implementing let us define few functions that we will require."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'Import libraries'\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import time\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import izip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'Utils functions'\n",
    "def splitData(test_size,cv, numpoints):\n",
    "    #This function from sklearn takes the length of the data and test size and returns bootstrapped indices \n",
    "    #depending on how many boostraps are required\n",
    "    '''\n",
    "    :param test_size: size of the test data required (value between 0 and 1).\n",
    "    :param cv: Number of re-shuffling.\n",
    "    :param numpoints: Total number of data points.\n",
    "    :return: indices of the shuffled splits.\n",
    "    '''\n",
    "    ss = ShuffleSplit(n=numpoints, n_iter=cv, test_size=test_size, random_state=32)\n",
    "    return ss\n",
    "\n",
    "def calAccuracy(pred,ytest):\n",
    "    '''\n",
    "    :param pred: vector containing all the predicted classes\n",
    "    :param ytest: vector containing all the true classes\n",
    "    :return: accuracy of classification\n",
    "    '''\n",
    "    count = 0\n",
    "    for i,j in izip(pred,ytest):\n",
    "        if i==j:\n",
    "            count +=1\n",
    "    return count/(len(ytest))\n",
    "\n",
    "def calgaussianprob(value,mean,std):\n",
    "    '''\n",
    "    :param value: Point for which the probability is to be found.\n",
    "    :param mean: mean of distribution.\n",
    "    :param std: standard deviation of distribution.\n",
    "    :return: probability of the value to fall in distribution with given mean and std.\n",
    "    '''\n",
    "    return (np.exp(- np.power((value-mean),2) / (2*np.power(std,2)) )) / (np.sqrt(2*np.power(std,2)*np.pi ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'Assume that the data is normally distributed'\n",
    "class naivebayesGaussian():\n",
    "    def __init__(self):\n",
    "        self.meanandstd = defaultdict(list)\n",
    "        self.classes = None\n",
    "        self.classCount = None\n",
    "        self.numFeatures = None\n",
    "        self.probXgivenClass = defaultdict(list)\n",
    "\n",
    "\n",
    "    def fit(self,Xtrain,ytrain):\n",
    "        start = time.time()\n",
    "        self.numFeatures = Xtrain.shape[1]\n",
    "        \n",
    "        'Get the classes and their respective counts, the counts will be used to calculate the class priors'\n",
    "        self.classes, self.classCount = np.unique(ytrain, return_counts=True)\n",
    "        \n",
    "        'Save the indices of data points belonging to each class'\n",
    "        indices = defaultdict(list)\n",
    "        \n",
    "        'Divide data according to classes'\n",
    "        for classes in self.classes:\n",
    "            indices[classes] =  np.where(ytrain == classes)[0]\n",
    "            'Calculate the mean and standard deviation of each feature respective to the class'\n",
    "            for i in range(self.numFeatures):\n",
    "                self.meanandstd[classes].append( ( Xtrain[indices[classes],:][:,i].mean(), Xtrain[indices[classes],:][:,i].std() ) )\n",
    "        end = time.time()\n",
    "        print 'Time taken to fit the data:', end-start\n",
    "        \n",
    "    def predict(self,Xtest):\n",
    "        start = time.time()\n",
    "        for classes, meanstd in self.meanandstd.iteritems():\n",
    "            for i in range(len(Xtest)):\n",
    "                prob = 1\n",
    "                for j in range(self.numFeatures):\n",
    "                    prob *= calgaussianprob(Xtest[i][j], meanstd[j][0], meanstd[j][1])\n",
    "                self.probXgivenClass[i].append(prob * (self.classCount[np.where(self.classes == classes)[0]][0]/self.classCount.sum() ) )\n",
    "\n",
    "        predictions = []\n",
    "        for i in range(len(Xtest)):\n",
    "            index = self.probXgivenClass[i].index(max(self.probXgivenClass[i]))\n",
    "            predictions.append(self.classes[index])\n",
    "        end = time.time()\n",
    "        print 'Time taken to predict:', end-start\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breastcancer = load_breast_cancer()\n",
    "numSamples, numFeat = breastcancer.data.shape\n",
    "ss = splitData(test_size=0.25,cv=1, numpoints=numSamples)\n",
    "for train_index, test_index in ss:\n",
    "    Xtrain = breastcancer.data[train_index, :]\n",
    "    ytrain = breastcancer.target[train_index].reshape((train_index.shape[0], 1))\n",
    "    Xtest = breastcancer.data[test_index, :]\n",
    "    ytest = breastcancer.target[test_index].reshape((test_index.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'Normalize the data to zero mean and unit variance'\n",
    "scalar = StandardScaler()\n",
    "Xtrain = scalar.fit_transform(Xtrain)\n",
    "Xtest = scalar.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running our algorithms:\n",
    "I have also compared the performance of my naive bayes implementation with sklearn naive bayes as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the data: 0.00693106651306\n",
      "Time taken to predict: 0.121052980423\n",
      "Accuracy: 92.3076923077\n"
     ]
    }
   ],
   "source": [
    "myNB = naivebayesGaussian()\n",
    "myNB.fit(Xtrain,ytrain)\n",
    "pred = myNB.predict(Xtest)\n",
    "print 'Accuracy:',calAccuracy(pred,ytest) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sklearn: 92.3076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(Xtrain,ytrain)\n",
    "pred = clf.predict(Xtest)\n",
    "print 'Accuracy of sklearn:',calAccuracy(pred,ytest) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Couclusion:\n",
    "The naive bayes that we have implmented gives the same accuracy as sklearn Gaussian Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refrences:\n",
    "My class notes and class slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
